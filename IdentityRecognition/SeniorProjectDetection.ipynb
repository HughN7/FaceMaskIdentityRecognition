{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeniorProjectDetection",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlPDXoq8TwNR"
      },
      "source": [
        "# Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrbaNWVyXuNk"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmMY-GsqTciD"
      },
      "source": [
        "weightFile = \"/content/drive/MyDrive/yolov3/FinalPartial/FinalPartial.weights\"\n",
        "configFile = \"/content/drive/MyDrive/yolov3/FinalPartial/yolov3_training.cfg\"\n",
        "namesFile = \"/content/drive/MyDrive/yolov3/FinalPartial/obj.names\"\n",
        "testImageLocation = '/content/drive/MyDrive/yolov3/testImage.jpg'\n",
        "testImageLocation2 = '/content/drive/MyDrive/yolov3/testImage2.jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOJyWDICTyoP"
      },
      "source": [
        "from google.colab.patches import cv2_imshow #cv2.imshow is broken in google colab therefore use this as replacement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZ11VObUbD_Y",
        "outputId": "f08c594a-a9ac-4b3a-aa43-58d8a26893ab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYsfYUJ8T-l4"
      },
      "source": [
        "# Define Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RyPJLfTUBwG"
      },
      "source": [
        "def recognizeFace(fileLocation):\n",
        "  net = cv2.dnn.readNet(weightFile, configFile) #pass in trained model weights and configuration file\n",
        "  classes = [] #store classes here\n",
        "\n",
        "  #load object class names\n",
        "  with open(namesFile, \"r\") as f:\n",
        "    classes = f.read().splitlines()\n",
        "\n",
        "  print(classes) #should be 4\n",
        "\n",
        "  #load test image\n",
        "  img = cv2.imread(fileLocation)\n",
        "  height, width, _ = img.shape\n",
        "\n",
        "  #prep image blob\n",
        "  blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False) #1/255 is scaling\n",
        "\n",
        "  net.setInput(blob) #input blob into network\n",
        "  output_layers_names = net.getUnconnectedOutLayersNames()\n",
        "  layerOutputs = net.forward(output_layers_names)\n",
        "\n",
        "  boxes = []\n",
        "  confidences = []\n",
        "  class_ids = []\n",
        "\n",
        "  for output in layerOutputs:\n",
        "    for detection in output:\n",
        "      scores = detection[5:] #starting from the sixth element to the end\n",
        "      class_id = np.argmax(scores) #extract highest score location\n",
        "      confidence = scores[class_id]\n",
        "      \n",
        "      if confidence > 0.5:\n",
        "        center_x = int(detection[0]*width)\n",
        "        center_y = int(detection[1]*height)\n",
        "        w = int(detection[2]*width)\n",
        "        h = int(detection[3]*height)\n",
        "\n",
        "        #upper left corner\n",
        "        x = int(center_x - w/2)\n",
        "        y = int(center_y - h/2)\n",
        "\n",
        "        boxes.append([x, y, w, h])\n",
        "        confidences.append(float(confidence))\n",
        "        class_ids.append(class_id)\n",
        "\n",
        "  indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  colors = np.random.uniform(0, 255, size=(len(boxes), 3))\n",
        "\n",
        "  if(len(indexes) > 0):\n",
        "    for i in indexes.flatten():\n",
        "      x, y, w, h = boxes[i]\n",
        "      label = str(classes[class_ids[i]])\n",
        "      confidence = str(round(confidences[i], 2))\n",
        "      color = colors[i]\n",
        "      cv2.rectangle(img, (x, y), (x+w, y+h), color, 2) #thickness is 2\n",
        "      cv2.putText(img, label + \" \" + confidence, (x, y + 20), font, 2, (255, 0, 0), 2)\n",
        "\n",
        "  else:\n",
        "    print(\"Indexes are empty!\")\n",
        "\n",
        "  #display image\n",
        "  cv2_imshow(img)\n",
        "  cv2.waitKey(0)\n",
        "  cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIVV1NY7UPFq"
      },
      "source": [
        "#Execution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4jbTAGPUQZl"
      },
      "source": [
        "recognizeFace(testImageLocation)\n",
        "#recognizeFace(testImageLocation2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}